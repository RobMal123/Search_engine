{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 2: Search Functionality\n",
    "Implement text-to-image search with cosine similarity and result analysis\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MultimodalSearchEngine:\n",
    "    def __init__(self, embeddings_dir=\"embeddings\", data_dir=\"data\"):\n",
    "        \"\"\"\n",
    "        Initialize the multimodal search engine\n",
    "        \n",
    "        Args:\n",
    "            embeddings_dir (str): Directory containing saved embeddings\n",
    "            data_dir (str): Directory containing the dataset\n",
    "        \"\"\"\n",
    "        self.embeddings_dir = embeddings_dir\n",
    "        self.data_dir = data_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load CLIP model for query processing\n",
    "        print(f\"Loading CLIP model on {self.device}...\")\n",
    "        self.model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load embeddings and metadata\n",
    "        self.image_embeddings = None\n",
    "        self.text_embeddings = None\n",
    "        self.image_text_pairs = None\n",
    "        self.metadata = None\n",
    "        self.load_embeddings()\n",
    "        \n",
    "        print(\"Search engine initialized successfully!\")\n",
    "    \n",
    "    def load_embeddings(self):\n",
    "        \"\"\"Load saved embeddings from disk\"\"\"\n",
    "        try:\n",
    "            with open(os.path.join(self.embeddings_dir, 'image_embeddings.pkl'), 'rb') as f:\n",
    "                self.image_embeddings = pickle.load(f)\n",
    "            \n",
    "            with open(os.path.join(self.embeddings_dir, 'text_embeddings.pkl'), 'rb') as f:\n",
    "                self.text_embeddings = pickle.load(f)\n",
    "            \n",
    "            with open(os.path.join(self.embeddings_dir, 'image_text_pairs.pkl'), 'rb') as f:\n",
    "                self.image_text_pairs = pickle.load(f)\n",
    "            \n",
    "            with open(os.path.join(self.embeddings_dir, 'metadata.json'), 'r') as f:\n",
    "                self.metadata = json.load(f)\n",
    "            \n",
    "            print(\"Embeddings loaded successfully!\")\n",
    "            print(f\"Available images: {self.metadata['num_images']}\")\n",
    "            print(f\"Available texts: {self.metadata['num_texts']}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"No saved embeddings found. Please run data preparation first.\")\n",
    "            raise\n",
    "    \n",
    "    def embed_text_query(self, text_query):\n",
    "        \"\"\"\n",
    "        Generate embedding for a text query\n",
    "        \n",
    "        Args:\n",
    "            text_query (str): Text query to embed\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Text embedding\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.processor(text=text_query, return_tensors=\"pt\", padding=True)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            text_features = self.model.get_text_features(**inputs)\n",
    "            text_embedding = text_features.cpu().numpy().flatten()\n",
    "        \n",
    "        return text_embedding\n",
    "    \n",
    "    def embed_image_query(self, image_path):\n",
    "        \"\"\"\n",
    "        Generate embedding for an image query\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Image embedding\n",
    "        \"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                inputs = self.processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                image_features = self.model.get_image_features(**inputs)\n",
    "                image_embedding = image_features.cpu().numpy().flatten()\n",
    "            \n",
    "            return image_embedding\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def search_text_to_image(self, text_query, top_k=5, similarity_metric='cosine'):\n",
    "        \"\"\"\n",
    "        Search for images using a text query\n",
    "        \n",
    "        Args:\n",
    "            text_query (str): Text query\n",
    "            top_k (int): Number of top results to return\n",
    "            similarity_metric (str): 'cosine' or 'euclidean'\n",
    "            \n",
    "        Returns:\n",
    "            list: List of dictionaries containing search results\n",
    "        \"\"\"\n",
    "        print(f\"Searching for: '{text_query}'\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embed_text_query(text_query)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        image_ids = list(self.image_embeddings.keys())\n",
    "        image_embeddings_array = np.array([self.image_embeddings[img_id] for img_id in image_ids])\n",
    "        \n",
    "        if similarity_metric == 'cosine':\n",
    "            similarities = cosine_similarity([query_embedding], image_embeddings_array)[0]\n",
    "        else:  # euclidean\n",
    "            distances = euclidean_distances([query_embedding], image_embeddings_array)[0]\n",
    "            similarities = 1 / (1 + distances)  # Convert distance to similarity\n",
    "        \n",
    "        # Get top-k results\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            image_id = image_ids[idx]\n",
    "            similarity_score = similarities[idx]\n",
    "            \n",
    "            # Find captions for this image\n",
    "            captions = []\n",
    "            for pair in self.image_text_pairs:\n",
    "                if pair['image_id'] == image_id:\n",
    "                    captions.append(pair['caption'])\n",
    "            \n",
    "            result = {\n",
    "                'rank': i + 1,\n",
    "                'image_id': image_id,\n",
    "                'similarity_score': similarity_score,\n",
    "                'captions': captions,\n",
    "                'image_path': self._get_image_path(image_id)\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def search_image_to_text(self, image_path, top_k=5, similarity_metric='cosine'):\n",
    "        \"\"\"\n",
    "        Search for text descriptions using an image query\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the query image\n",
    "            top_k (int): Number of top results to return\n",
    "            similarity_metric (str): 'cosine' or 'euclidean'\n",
    "            \n",
    "        Returns:\n",
    "            list: List of dictionaries containing search results\n",
    "        \"\"\"\n",
    "        print(f\"Searching for image: {image_path}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embed_image_query(image_path)\n",
    "        if query_embedding is None:\n",
    "            return []\n",
    "        \n",
    "        # Calculate similarities with text embeddings\n",
    "        text_ids = list(self.text_embeddings.keys())\n",
    "        text_embeddings_array = np.array([self.text_embeddings[text_id] for text_id in text_ids])\n",
    "        \n",
    "        if similarity_metric == 'cosine':\n",
    "            similarities = cosine_similarity([query_embedding], text_embeddings_array)[0]\n",
    "        else:  # euclidean\n",
    "            distances = euclidean_distances([query_embedding], text_embeddings_array)[0]\n",
    "            similarities = 1 / (1 + distances)  # Convert distance to similarity\n",
    "        \n",
    "        # Get top-k results\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            text_id = text_ids[idx]\n",
    "            similarity_score = similarities[idx]\n",
    "            \n",
    "            # Find the corresponding caption and image\n",
    "            caption = None\n",
    "            image_id = None\n",
    "            for pair in self.image_text_pairs:\n",
    "                if pair['text_id'] == text_id:\n",
    "                    caption = pair['caption']\n",
    "                    image_id = pair['image_id']\n",
    "                    break\n",
    "            \n",
    "            result = {\n",
    "                'rank': i + 1,\n",
    "                'text_id': text_id,\n",
    "                'caption': caption,\n",
    "                'image_id': image_id,\n",
    "                'similarity_score': similarity_score,\n",
    "                'image_path': self._get_image_path(image_id) if image_id else None\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _get_image_path(self, image_id):\n",
    "        \"\"\"Get the file path for an image ID\"\"\"\n",
    "        # Try different possible paths\n",
    "        possible_paths = [\n",
    "            os.path.join(self.data_dir, \"Images\", image_id),\n",
    "            os.path.join(self.data_dir, image_id),\n",
    "            image_id\n",
    "        ]\n",
    "        \n",
    "        for path in possible_paths:\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def display_search_results(self, results, query, search_type='text_to_image'):\n",
    "        \"\"\"\n",
    "        Display search results with images and analysis\n",
    "        \n",
    "        Args:\n",
    "            results (list): Search results\n",
    "            query (str): Original query\n",
    "            search_type (str): Type of search performed\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Search Results for '{query}' ===\")\n",
    "        print(f\"Search type: {search_type}\")\n",
    "        print(f\"Found {len(results)} results\\n\")\n",
    "        \n",
    "        # Create subplot\n",
    "        fig, axes = plt.subplots(1, len(results), figsize=(4*len(results), 4))\n",
    "        if len(results) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Try to display image\n",
    "            image_path = result.get('image_path')\n",
    "            if image_path and os.path.exists(image_path):\n",
    "                try:\n",
    "                    img = Image.open(image_path)\n",
    "                    ax.imshow(img)\n",
    "                    ax.axis('off')\n",
    "                except Exception as e:\n",
    "                    ax.text(0.5, 0.5, f\"Image not found\\n{image_path}\", \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.axis('off')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f\"Image not found\\n{result.get('image_id', 'Unknown')}\", \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # Add title with rank and similarity score\n",
    "            title = f\"Rank {result['rank']}\\nScore: {result['similarity_score']:.4f}\"\n",
    "            ax.set_title(title, fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(\"\\nDetailed Results:\")\n",
    "        for result in results:\n",
    "            print(f\"\\nRank {result['rank']}:\")\n",
    "            print(f\"  Similarity Score: {result['similarity_score']:.4f}\")\n",
    "            \n",
    "            if search_type == 'text_to_image':\n",
    "                print(f\"  Image ID: {result['image_id']}\")\n",
    "                print(f\"  Captions:\")\n",
    "                for j, caption in enumerate(result['captions']):\n",
    "                    print(f\"    {j+1}. {caption}\")\n",
    "            else:  # image_to_text\n",
    "                print(f\"  Caption: {result['caption']}\")\n",
    "                print(f\"  Image ID: {result['image_id']}\")\n",
    "    \n",
    "    def analyze_search_results(self, results, query):\n",
    "        \"\"\"\n",
    "        Analyze search results and provide insights\n",
    "        \n",
    "        Args:\n",
    "            results (list): Search results\n",
    "            query (str): Original query\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Analysis of Search Results for '{query}' ===\")\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No results found.\")\n",
    "            return\n",
    "        \n",
    "        # Score analysis\n",
    "        scores = [result['similarity_score'] for result in results]\n",
    "        print(f\"Score Statistics:\")\n",
    "        print(f\"  Highest score: {max(scores):.4f}\")\n",
    "        print(f\"  Lowest score: {min(scores):.4f}\")\n",
    "        print(f\"  Average score: {np.mean(scores):.4f}\")\n",
    "        print(f\"  Score range: {max(scores) - min(scores):.4f}\")\n",
    "        \n",
    "        # Content analysis\n",
    "        print(f\"\\nContent Analysis:\")\n",
    "        \n",
    "        # Extract common words from captions\n",
    "        all_captions = []\n",
    "        for result in results:\n",
    "            if 'captions' in result:\n",
    "                all_captions.extend(result['captions'])\n",
    "            elif 'caption' in result:\n",
    "                all_captions.append(result['caption'])\n",
    "        \n",
    "        if all_captions:\n",
    "            # Simple word frequency analysis\n",
    "            words = []\n",
    "            for caption in all_captions:\n",
    "                words.extend(caption.lower().split())\n",
    "            \n",
    "            from collections import Counter\n",
    "            word_freq = Counter(words)\n",
    "            common_words = word_freq.most_common(5)\n",
    "            \n",
    "            print(f\"  Most common words in results: {[word for word, freq in common_words]}\")\n",
    "        \n",
    "        # Query relevance analysis\n",
    "        print(f\"\\nQuery Relevance Analysis:\")\n",
    "        query_words = set(query.lower().split())\n",
    "        \n",
    "        relevant_results = 0\n",
    "        for result in results:\n",
    "            captions = result.get('captions', [result.get('caption', '')])\n",
    "            caption_words = set()\n",
    "            for caption in captions:\n",
    "                caption_words.update(caption.lower().split())\n",
    "            \n",
    "            # Check for word overlap\n",
    "            overlap = query_words.intersection(caption_words)\n",
    "            if overlap:\n",
    "                relevant_results += 1\n",
    "                print(f\"  Rank {result['rank']}: {len(overlap)} word(s) match: {list(overlap)}\")\n",
    "        \n",
    "        print(f\"  Results with word overlap: {relevant_results}/{len(results)}\")\n",
    "        \n",
    "        # Model behavior insights\n",
    "        print(f\"\\nModel Behavior Insights:\")\n",
    "        if max(scores) > 0.8:\n",
    "            print(\"  - High similarity scores suggest the model found very relevant matches\")\n",
    "        elif max(scores) > 0.6:\n",
    "            print(\"  - Moderate similarity scores suggest reasonable matches\")\n",
    "        else:\n",
    "            print(\"  - Low similarity scores suggest the query may be challenging for the model\")\n",
    "        \n",
    "        if len(set(scores)) < len(scores):\n",
    "            print(\"  - Some results have identical scores, indicating similar relevance\")\n",
    "        \n",
    "        print(f\"  - The model successfully mapped text concepts to visual features\")\n",
    "    \n",
    "    def interactive_search(self):\n",
    "        \"\"\"Interactive search interface\"\"\"\n",
    "        print(\"=== Interactive Multimodal Search ===\")\n",
    "        print(\"Type 'quit' to exit\")\n",
    "        \n",
    "        while True:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            query = input(\"Enter your text query: \").strip()\n",
    "            \n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                print(\"Please enter a valid query.\")\n",
    "                continue\n",
    "            \n",
    "            # Perform search\n",
    "            results = self.search_text_to_image(query, top_k=5)\n",
    "            \n",
    "            if results:\n",
    "                # Display results\n",
    "                self.display_search_results(results, query)\n",
    "                \n",
    "                # Analyze results\n",
    "                self.analyze_search_results(results, query)\n",
    "            else:\n",
    "                print(\"No results found for your query.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the search engine\"\"\"\n",
    "    print(\"=== Multimodal Search Engine ===\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize search engine\n",
    "        search_engine = MultimodalSearchEngine()\n",
    "        \n",
    "        # Example searches\n",
    "        example_queries = [\n",
    "            \"a dog running in the park\",\n",
    "            \"people playing sports\",\n",
    "            \"food on a table\",\n",
    "            \"a car on the road\",\n",
    "            \"children playing\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nRunning example searches...\")\n",
    "        for query in example_queries:\n",
    "            results = search_engine.search_text_to_image(query, top_k=3)\n",
    "            if results:\n",
    "                search_engine.display_search_results(results, query)\n",
    "                search_engine.analyze_search_results(results, query)\n",
    "                print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Interactive mode\n",
    "        print(\"Starting interactive search mode...\")\n",
    "        search_engine.interactive_search()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing search engine: {e}\")\n",
    "        print(\"Please make sure you have run the data preparation first.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
